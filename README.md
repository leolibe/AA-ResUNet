# Tiny-AAResUNet: An Attention Augmented Convolution-based Tiny-Residual UNet for Road Extraction
Abstract: Recently remote sensing images have become more popular due to improved image quality and resolution. These images have been shown to be a valuable data source for road extraction applications like intelligent transportation systems, road maintenance, and road map making. In recent decades, the use of highly significant deep learning in automatic road extraction from these images has been a hot research area. However, highly accurate road extractions from remote sensing images remain a challenge because they are cluttered in the background and have widely different shapes and complex connectivities. This paper proposes novel tiny attention augmented convolution-based residual UNet architecture (Tiny-AAResUNet) for road extraction, which adopts powerful features of the self-attention mechanism and advantageous properties of residual UNet structure. The self-attention mechanism uses attention-augmented convolutional operation to capture long-range global information; however, traditional convolution has a fundamental disadvantage: it only performs on local information. Therefore, we use the attention-augmented convolutional layer as an alternative to standard convolution layers to obtain more discriminant feature representations. It allows the developing of a network with fewer parameters. We also adopt improved residual units in standard ResUNet to the speedup training process and enhance the segmentation accuracy of the network. Experimental results on Massachusetts, DeepGlobe Challenge, and UAV Road Dataset show that the Tiny-AAResUNet performs well in road extraction, with Intersection over Union (IoU) (94.27%), lower trainable parameters (1.20 M), and inference time (1.14 sec). Comparative results on the proposed method have outperformed in road extraction with ten recently established deep learning approaches.
